variables:
  DOCKER_DRIVER: overlay
  VER: v$CI_PIPELINE_ID
  DOCKER_TLS_CERTDIR: ''

stages:
  - tests
  - build
  - image
  - deploy-dev
  - deploy-prod

1-unit:
  stage: tests
  image: node:18.19.1-alpine3.19
  only:
    - main
    - develop
    - /^release/[0-9]/
  script:
    #- npm install --legacy-peer-deps
    #- npm run test
    - echo Executando testes

2-style:
  stage: tests
  image: node:18.19.1-alpine3.19
  only:
    - main
    - develop
    - /^release/[0-9]/
  script:
    - npm install --legacy-peer-deps
    - npm run lint

3-sonar:
  stage: tests
  image:
    name: sonarsource/sonar-scanner-cli:5.0
    entrypoint: [""]
  variables:
    SONAR_USER_HOME: "${CI_PROJECT_DIR}/.sonar"  # Defines the location of the analysis task cache
    GIT_DEPTH: "0"  # Tells git to fetch all the branches of the project, required by the analysis task
  cache:
    key: "${CI_JOB_NAME}"
    paths:
      - .sonar/cache
  script:
    - sonar-scanner
  allow_failure: true
  only:
    - develop # or the name of your main branch

build_app:
  stage: build
  image: node:18.19.1-alpine3.19
  only:
    - main
    - develop
    - /^release/[0-9]/
  script:
    - npm install --legacy-peer-deps
    - npm run build
  artifacts:
    expire_in: 3 days

1-image_build:
  image: docker:20.10.8-alpine3.13
  stage: image
  only:
    - main
    - develop
    - /^release/[0-9]/
  services:
    - docker:20.10.8-dind
  script:
    - docker build -f docker/dockerfile -t $CI_REGISTRY/$CI_PROJECT_PATH:$VER .
  allow_failure: false

2-image_check:
  image:
    name: aquasec/trivy:latest
    entrypoint: [""]
  variables:
    GIT_STRATEGY: none
    TRIVY_NO_PROGRESS: "true"
  stage: image
  only:
    - main
    - develop
    - /^release/[0-9]/
  services:
    - docker:20.10.8-dind
  dependencies:
    - 1-image_build
  script:
    - trivy image --security-checks vuln,config,secret --severity MEDIUM,HIGH,CRITICAL $CI_REGISTRY/$CI_PROJECT_PATH:$VER
  allow_failure: false

3-image_push_dev:
  image: docker:20.10.8-alpine3.13
  stage: image
  only:
    - develop
  dependencies:
    - 1-image_build
  services:
    - docker:20.10.8-dind
  before_script:
    - docker login $CI_REGISTRY -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASS
  script:
    - docker image tag $CI_REGISTRY/$CI_PROJECT_PATH:$VER $CI_REGISTRY/$CI_PROJECT_PATH:develop
    - docker push $CI_REGISTRY/$CI_PROJECT_PATH:$VER
    - docker push $CI_REGISTRY/$CI_PROJECT_PATH:develop
  allow_failure: false

3-image_push_prod:
  image: docker:20.10.8-alpine3.13
  stage: image
  only:
    - main
  dependencies:
    - 1-image_build
  services:
    - docker:20.10.8-dind
  before_script:
    - docker login $CI_REGISTRY -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASS
  script:
    - docker image tag $CI_REGISTRY/$CI_PROJECT_PATH:$VER $CI_REGISTRY/$CI_PROJECT_PATH:latest
    - docker push $CI_REGISTRY/$CI_PROJECT_PATH:$VER
    - docker push $CI_REGISTRY/$CI_PROJECT_PATH:latest
  allow_failure: false

deploy_dev:
  stage: deploy-dev
  only:
    - develop
  image:
    name: $CI_REGISTRY/celsonery/kubectl
  before_script:
    - echo $KUBE_CREDENTIALS | base64 -d > kubeconfig
    - export KUBECONFIG=kubeconfig
  script:
    - kubectl set image -n bagarote-dev deployments/db-sync db-sync=$CI_REGISTRY/$CI_PROJECT_PATH:$VER

rollback_dev:
  stage: deploy-dev
  when: manual
  only:
    - develop
  image:
    name: $CI_REGISTRY/celsonery/kubectl
  before_script:
    - echo $KUBE_CREDENTIALS | base64 -d > kubeconfig
    - export KUBECONFIG=kubeconfig
  script:
    - kubectl rollout undo -n bagarote-dev deployments/db-sync

deploy_prod:
  stage: deploy-prod
  when: manual
  only:
    - main
  image:
    name: $CI_REGISTRY/celsonery/kubectl
  before_script:
    - echo $KUBE_CREDENTIALS | base64 -d > kubeconfig
    - export KUBECONFIG=kubeconfig
  script:
    - kubectl set image -n bagarote-prod deployments/db-sync db-sync=$CI_REGISTRY/$CI_PROJECT_PATH:$VER

rollback_prod:
  stage: deploy-prod
  when: manual
  only:
    - main
  image:
    name: $CI_REGISTRY/celsonery/kubectl
  before_script:
    - echo $KUBE_CREDENTIALS | base64 -d > kubeconfig
    - export KUBECONFIG=kubeconfig
  script:
    - kubectl rollout undo -n bagarote-prod deployments/db-sync

image_clean:
  image: docker:25.0.3-alpine3.19
  stage: image
  only:
    - develop
    - /^release/[0-9]/
    - main
  services:
    - docker:25.0.3-dind-alpine3.19
  before_script:
    - docker login $CI_REGISTRY -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASS
  script:
    - echo "Limpando imagens antigas e mantenas apenas develop|homolog|latest"
    - for i in $(printf "%s\n" `docker image ls | grep $CI_REGISTRY/$CI_PROJECT_PATH | awk '{print $3}'` `docker image ls | grep $CI_REGISTRY/$CI_PROJECT_PATH | egrep "latest|develop|homolog" |  awk '{print $3}'` | sort | uniq -u);
      do
        docker rmi $i;
      done
  allow_failure: false
